{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import random\n",
    "import cv2\n",
    "import scipy.misc\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取mnist数据集\n",
    "def read_mnist_data(file_path):\n",
    "    mnist_data = input_data.read_data_sets(file_path,one_hot=True)\n",
    "    train_data = mnist_data.train.images\n",
    "    train_labels = mnist_data.train.labels\n",
    "    test_data = mnist_data.test.images\n",
    "    test_labels = mnist_data.test.labels\n",
    "    valid_data,valid_labels = mnist_data.validation.images,mnist_data.validation.labels\n",
    "    return train_data,train_labels,test_data,test_labels,valid_data,valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并训练集和检验集\n",
    "def combination_train_valid(train_data,train_labels,valid_data,valid_labels):\n",
    "    train_data = np.vstack((train_data,valid_data))\n",
    "    train_labels = np.vstack((train_labels,valid_labels))\n",
    "    return train_data,train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看mnist数据集中的手写数字\n",
    "def image_show(image_data):\n",
    "    temp_image = image_data.reshape(28,28)\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(temp_image,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存mnist数据\n",
    "def save_mnist_data(image,file_path,number,data_type,label):\n",
    "    #mnist = input_data.read_data_sets('./MNIST_data/',one_hot=True)\n",
    "    if os.path.exists(file_path) is False:\n",
    "        os.makedirs(file_path)\n",
    "    temp_image = image.reshape(28,28)\n",
    "    temp_img_file = file_path + data_type + '_mnist_data_%d_label_%d.jpg'%(number+1,label)\n",
    "    Image.fromarray((temp_image*255).astype('uint8'),mode='L').convert('RGB').save(temp_img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存所有图片\n",
    "def save_images(file_path_1,file_path_2,train_data,train_labels,test_data,test_labels):\n",
    "    train_length = len(train_data)\n",
    "    for i in range(train_length):\n",
    "        save_mnist_data(train_data[i],file_path_1,i,'train',int(np.where(train_labels[i]==1)[0]))\n",
    "    test_length = len(test_data)\n",
    "    for j in range(test_length):\n",
    "        save_mnist_data(test_data[j],file_path_2,j,'test',int(np.where(test_labels[j]==1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据变换函数\n",
    "def mnist_transform_function(image,resize_type,filepath,number,label):\n",
    "    #先构建64*64的背景图片\n",
    "    temp_fig = np.zeros([64,64])\n",
    "    plt.imshow(temp_fig,cmap='gray')\n",
    "    #plt.imsave('temp.png',temp_fig,cmap='gray')\n",
    "    '''\n",
    "    cv2.imshow('background',temp_fig)\n",
    "    cv2.imwrite('background.png',temp_fig)\n",
    "    '''\n",
    "    #将28*28的图像转为8*8\n",
    "    temp_img = image.reshape(28,28)\n",
    "    temp_img_resize = cv2.resize(temp_img,(resize_type,resize_type),interpolation=cv2.INTER_NEAREST)\n",
    "    #plt.imshow(temp_img,cmap='gray')\n",
    "    #plt.imshow(temp_img_resize,cmap='gray')\n",
    "    #将resize后的图片随机放入background的某一个地方\n",
    "    positions = 64 / resize_type\n",
    "    height = random.randint(0,positions-1) * resize_type\n",
    "    width = random.randint(0,positions-1) * resize_type\n",
    "    #print(height,width)\n",
    "    temp_fig[height:height+resize_type,width:width+resize_type] = temp_img_resize\n",
    "    #plt.imshow(temp_fig,cmap='gray')\n",
    "    temp_fig_path = filepath+'MNIST_train_%d_label_%d.png'%(number,label)\n",
    "    plt.imsave(temp_fig_path,temp_fig,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理所有的数据\n",
    "def local_task_data(train_data,train_labels,resize_type,filepath):\n",
    "    train_length = len(train_data)\n",
    "    for i in range(train_length):\n",
    "        mnist_transform_function(train_data[i],resize_type,filepath,i,int(np.where(train_labels[i]==1)[0]))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif __name__ == \"__main__\":\\n    file_path = \\'./MNIST_data/\\'\\n    train_data,train_labels,test_data,test_labels,valid_data,valid_labels = read_mnist_data(file_path)\\n    #print(train_data.shape,train_labels.shape,test_data.shape,test_labels.shape,valid_data.shape,valid_labels.shape)\\n    train_data,train_labels = combination_train_valid(train_data,train_labels,valid_data,valid_labels)\\n    print(train_data.shape,train_labels.shape)\\n    image_file_path = \\'./MNIST_IMG/\\'\\n    train_file_path = \\'./MNIST_IMG/train/\\'\\n    test_file_path = \\'./MNIST_IMG/test/\\'\\n    #save_images(train_file_path,test_file_path,train_data,train_labels,test_data,test_labels)\\n    #mnist_transform_function(train_data[2],8)\\n    transform_train_data_filepath = \\'./MNIST_global_task/train/\\'\\n    transform_test_data_filepath = \\'./MNIST_global_task/test/\\'\\n    local_task_data(test_data,test_labels,32,transform_test_data_filepath)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = './MNIST_data/'\n",
    "    train_data,train_labels,test_data,test_labels,valid_data,valid_labels = read_mnist_data(file_path)\n",
    "    #print(train_data.shape,train_labels.shape,test_data.shape,test_labels.shape,valid_data.shape,valid_labels.shape)\n",
    "    train_data,train_labels = combination_train_valid(train_data,train_labels,valid_data,valid_labels)\n",
    "    print(train_data.shape,train_labels.shape)\n",
    "    image_file_path = './MNIST_IMG/'\n",
    "    train_file_path = './MNIST_IMG/train/'\n",
    "    test_file_path = './MNIST_IMG/test/'\n",
    "    #save_images(train_file_path,test_file_path,train_data,train_labels,test_data,test_labels)\n",
    "    #mnist_transform_function(train_data[2],8)\n",
    "    transform_train_data_filepath = './MNIST_global_task/train/'\n",
    "    transform_test_data_filepath = './MNIST_global_task/test/'\n",
    "    local_task_data(test_data,test_labels,32,transform_test_data_filepath)\n",
    "'''   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model,load_model\n",
    "from keras.layers import Dense,Dropout,Lambda,Flatten,Conv2D,MaxPool2D,Input,AveragePooling2D\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取文件夹下的所有数据\n",
    "'''\n",
    "def read_transfor_data(filepath):\n",
    "    labels = []\n",
    "    img_data = []\n",
    "    for filename in os.listdir(r\"./\"+filepath):\n",
    "        labels.append(int(filename[-5]))\n",
    "        img = cv2.imread(filepath + \"/\" + filename)\n",
    "        img_data.append(img)\n",
    "    #print(img_data[0].shape)\n",
    "    #print(labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据变换函数\n",
    "def img_transform_function(image,resize_type):\n",
    "    #先构建64*64的背景图片\n",
    "    temp_fig = np.zeros([64,64])\n",
    "    #plt.imshow(temp_fig,cmap='gray')\n",
    "    #plt.imsave('temp.png',temp_fig,cmap='gray')\n",
    "    '''\n",
    "    cv2.imshow('background',temp_fig)\n",
    "    cv2.imwrite('background.png',temp_fig)\n",
    "    '''\n",
    "    #将28*28的图像转为8*8\n",
    "    temp_img = image.reshape(28,28)\n",
    "    temp_img_resize = cv2.resize(temp_img,(resize_type,resize_type),interpolation=cv2.INTER_NEAREST)\n",
    "    #plt.imshow(temp_img,cmap='gray')\n",
    "    #plt.imshow(temp_img_resize,cmap='gray')\n",
    "    #将resize后的图片随机放入background的某一个地方\n",
    "    positions = 64 / resize_type\n",
    "    height = random.randint(0,positions-1) * resize_type\n",
    "    width = random.randint(0,positions-1) * resize_type\n",
    "    #print(height,width)\n",
    "    temp_fig[height:height+resize_type,width:width+resize_type] = temp_img_resize\n",
    "    #plt.imshow(temp_fig,cmap='gray')\n",
    "    #temp_fig_path = filepath+'MNIST_train_%d_label_%d.png'%(number,label)\n",
    "    #plt.imsave(temp_fig_path,temp_fig,cmap='gray')\n",
    "    plt.imshow(temp_fig,cmap='gray')\n",
    "    return temp_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理所有的图片\n",
    "def handle_all_images(x_train,resize_type):\n",
    "    x_train_transformed = []\n",
    "    for i in x_train:\n",
    "        temp_img = img_transform_function(i,resize_type)\n",
    "        x_train_transformed.append(temp_img)\n",
    "    x_train_transformed = np.array(x_train_transformed)\n",
    "    return x_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.001,rho=0.9,epsilon=1e-08,decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvAC_Model_Construction_Wide_base(r):\n",
    "    input_img = Input(shape=(64,64,1))\n",
    "    #representation层（使用3*3的卷积）\n",
    "    X1 = Conv2D(10,(3,3),activation='relu',padding='same')(input_img)\n",
    "    \n",
    "    X1 = Conv2D(4*r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "    \n",
    "    X1 = Conv2D(4*r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "    \n",
    "    X1 = Conv2D(2*r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "\n",
    "    X1 = Conv2D(2*r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "\n",
    "    X1 = Conv2D(r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "\n",
    "    X1 = Conv2D(r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "    \n",
    "    X1 = Flatten()(X1)\n",
    "    X1 = Dense(10,activation=\"relu\")(X1)\n",
    "    X1 = Dropout(0.5)(X1)\n",
    "    ConvAC_output = Dense(10,activation = \"softmax\")(X1)\n",
    "    \n",
    "    ConvAC_model = Model(input_img,ConvAC_output)\n",
    "    return ConvAC_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvAC_Model_Construction_Wide_tip(r):\n",
    "    input_img = Input(shape=(64,64,1))\n",
    "    #representation层（使用3*3的卷积）\n",
    "    X1 = Conv2D(10,(3,3),activation='relu',padding='same')(input_img)\n",
    "    \n",
    "    X1 = Conv2D(r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "    \n",
    "    X1 = Conv2D(r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "    \n",
    "    X1 = Conv2D(2*r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "\n",
    "    X1 = Conv2D(2*r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "\n",
    "    X1 = Conv2D(4*r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "\n",
    "    X1 = Conv2D(4*r,(1,1),activation='relu')(X1)\n",
    "    X1 = MaxPool2D(pool_size=(2,2),strides=2)(X1)\n",
    "    X1 = Dropout(0.25)(X1)\n",
    "    \n",
    "    X1 = Flatten()(X1)\n",
    "    X1 = Dense(10,activation=\"relu\")(X1)\n",
    "    X1 = Dropout(0.5)(X1)\n",
    "    ConvAC_output = Dense(10,activation = \"softmax\")(X1)\n",
    "    \n",
    "    ConvAC_model = Model(input_img,ConvAC_output)\n",
    "    return ConvAC_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvAC_model_fit_wide_base(X_train,y_train,X_test,y_test,epochs,batch_size,r,optimizer):\n",
    "    ConvAC_model = ConvAC_Model_Construction_Wide_tip(r)\n",
    "    ConvAC_model.compile(optimizer = optimizer,\n",
    "                         loss = \"categorical_crossentropy\",\n",
    "                         metrics = [\"accuracy\"])\n",
    "    hist_temp = ConvAC_model.fit(X_train,y_train,\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose = 1,\n",
    "                                 )\n",
    "    train_accuracy = hist_temp.history['acc'][-1]\n",
    "    test_result = ConvAC_model.evaluate(x=X_test,y=y_test)\n",
    "    test_accuracy = test_result[1]\n",
    "    return train_accuracy,test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvAC_model_fit_wide_tip(X_train,y_train,X_test,y_test,epochs,batch_size,r,optimizer):\n",
    "    ConvAC_model = ConvAC_Model_Construction_Wide_base(r)\n",
    "    ConvAC_model.compile(optimizer = optimizer,\n",
    "                         loss = \"categorical_crossentropy\",\n",
    "                         metrics = [\"accuracy\"])\n",
    "    hist_temp = ConvAC_model.fit(X_train,y_train,\n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose = 1,\n",
    "                                 )\n",
    "    train_accuracy = hist_temp.history['acc']\n",
    "    test_result = ConvAC_model.evaluate(x=X_test,y=y_test)\n",
    "    test_accuracy = test_result[1]\n",
    "    return train_accuracy,test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_155/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,40].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1658\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1659\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1660\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_155/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,40].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-f21201b8dde1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[0mConvAC_model_fit_wide_base\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-33-556d2ae02682>\u001b[0m in \u001b[0;36mConvAC_model_fit_wide_base\u001b[1;34m(X_train, y_train, X_test, y_test, epochs, batch_size, r, optimizer)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mConvAC_model_fit_wide_base\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mConvAC_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvAC_Model_Construction_Wide_tip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     ConvAC_model.compile(optimizer = optimizer,\n\u001b[0;32m      4\u001b[0m                          \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                          metrics = [\"accuracy\"])\n",
      "\u001b[1;32m<ipython-input-32-fab8c3044fcb>\u001b[0m in \u001b[0;36mConvAC_Model_Construction_Wide_tip\u001b[1;34m(r)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMaxPool2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mX1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    203\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                                         data_format=self.data_format)\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\layers\\pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[1;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[0;32m    266\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[0;32m    267\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m                           pool_mode='max')\n\u001b[0m\u001b[0;32m    269\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[1;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[0;32m   3976\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[0;32m   3977\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3978\u001b[1;33m                            data_format=tf_data_format)\n\u001b[0m\u001b[0;32m   3979\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'avg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3980\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   2746\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2747\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2748\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   2749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[1;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[0;32m   5134\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   5135\u001b[0m         \u001b[1;34m\"MaxPool\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5136\u001b[1;33m                    data_format=data_format, name=name)\n\u001b[0m\u001b[0;32m   5137\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    789\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3298\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3299\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3300\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3301\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1821\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1822\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1823\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1662\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 2 from 1 for 'max_pooling2d_155/MaxPool' (op: 'MaxPool') with input shapes: [?,1,1,40]."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    (X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "    assert K.image_data_format() == \"channels_last\"\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "#     resize_type_1 = 8\n",
    "#     resize_type_2 = 32\n",
    "#     a = img_transform_function(X_train[0],resize_type_1)\n",
    "#     b = img_transform_function(X_train[1],resize_type_2)\n",
    "#     x_transformed_train_local = handle_all_images(X_train,resize_type_1)\n",
    "#     x_transformed_train_local = np.reshape(x_transformed_train_local,(-1,64,64,1))/255\n",
    "#     x_transformed_test_local = handle_all_images(X_test,resize_type_1)\n",
    "#     x_transformed_test_local = np.reshape(x_transformed_test_local,(-1,64,64,1))/255\n",
    "#     x_transformed_train_global = handle_all_images(X_train,resize_type_2)\n",
    "#     x_transformed_train_global = np.reshape(x_transformed_train_global,(-1,64,64))/255\n",
    "#     x_transformed_test_global = handle_all_images(X_test,resize_type_2)\n",
    "#     x_transformed_test_global = np.reshape(x_transformed_test_global,(-1,64,64))/255\n",
    "#     np.save('local_task_mnist_train',x_transformed_train_local)\n",
    "#     np.save('local_task_mnist_test',x_transformed_test_local)\n",
    "#     np.save('global_task_mnist_train',x_transformed_train_global)\n",
    "#     np.save('global_task_mnist_test',x_transformed_test_global)\n",
    "    global_task_train = np.load('global_task_mnist_train.npy')\n",
    "    global_task_test = np.load('global_task_mnist_test.npy')\n",
    "    print(\"global task 数据加载完毕！\")\n",
    "    epochs = 3\n",
    "    batch_size = 100\n",
    "    wide_base_train_accuracy = []\n",
    "    wide_base_test_accuracy = []\n",
    "    wide_tip_train_accuracy = []\n",
    "    wide_tip_test_accuracy = []\n",
    "    for r in range(5,31,5):\n",
    "        base_train_acc,base_test_acc = ConvAC_model_fit_wide_base(global_task_train,y_train,global_task_test,y_test,epochs,batch_size,r,optimizer)\n",
    "        wide_base_train_accuracy.append(base_train_acc)\n",
    "        wide_base_test_accuracy.append(base_test_acc)\n",
    "        tip_train_acc,tip_test_acc = ConvAC_model_fit_wide_tip(global_task_train,y_train,global_task_test,y_test,epochs,batch_size,r,optimizer)\n",
    "        wide_tip_train_accuracy.append(tip_train_acc)\n",
    "        wide_tip_test_accuracy.append(tip_test_acc)\n",
    "        print(\"global task %d round is finished.\"%(r))\n",
    "    np.save('wide_base_train_accuracy',np.array(wide_base_train_accuracy))\n",
    "    np.save('wide_base_test_accuracy',np.array(wide_base_test_accuracy))\n",
    "    np.save('wide_tip_train_accuracy',np.array(wide_tip_train_accuracy))\n",
    "    np.save('wide_tip_test_accuracy',np.array(wide_tip_test_accuracy))\n",
    "    #local task result\n",
    "    local_task_train = np.load(\"local_task_mnist_train.npy\")\n",
    "    local_task_test = np.load(\"local_task_mnist_test.npy\")\n",
    "    print(\"local task 数据加载完毕！\")\n",
    "    local_wide_base_train_accuracy = []\n",
    "    local_wide_base_test_accuracy = []\n",
    "    local_wide_tip_train_accuracy = []\n",
    "    local_wide_tip_test_accuracy = []\n",
    "    for k in range(5,31,5):\n",
    "        local_base_train_acc,local_base_test_acc = ConvAC_model_fit_wide_base(local_task_train,y_train,local_task_test,y_test,epochs,batch_size,k,optimizer)\n",
    "        local_wide_base_train_accuracy.append(local_base_train_acc)\n",
    "        local_wide_base_test_accuracy.append(local_base_test_acc)\n",
    "        local_tip_train_acc,local_tip_test_acc = ConvAC_model_fit_wide_tip(local_task_train,y_train,local_task_test,y_test,epochs,batch_size,k,optimizer)\n",
    "        local_wide_tip_train_accuracy.append(local_tip_train_acc)\n",
    "        local_wide_tip_test_accuracy.append(local_tip_test_acc)   \n",
    "        print(\"local task %d round is finished.\"%(k))\n",
    "    np.save('local_wide_base_train_accuracy',np.array(local_wide_base_train_accuracy))\n",
    "    np.save('local_wide_base_test_accuracy',np.array(local_wide_base_test_accuracy))\n",
    "    np.save('local_wide_tip_train_accuracy',np.array(local_wide_tip_train_accuracy))\n",
    "    np.save('local_wide_tip_test_accuracy',np.array(local_wide_tip_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wide_base_train_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-28580c455f92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwide_base_train_accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wide_base_train_accuracy' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(6, 31, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
