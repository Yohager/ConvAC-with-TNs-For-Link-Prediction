{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-34a154abc92d>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MINST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MINST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Image shape: (28, 28, 1)\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "minst_data = input_data.read_data_sets('MINST_data/',reshape=False)\n",
    "X_train, y_train = minst_data.train.images, minst_data.train.labels\n",
    "X_validation, y_validation = minst_data.validation.images, minst_data.validation.labels\n",
    "X_test, y_test = minst_data.test.images, minst_data.test.labels\n",
    "\n",
    "assert (len(X_train) == len(y_train))\n",
    "assert (len(X_validation) == len(y_validation))\n",
    "assert (len(X_test) == len(y_test))\n",
    "\n",
    "print(\"Image shape: {}\".format(X_train[0].shape))\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.pad(X_train,((0,0),(2,2),(2,2),(0,0)),'constant')\n",
    "X_validation = np.pad(X_validation,((0,0),(2,2),(2,2),(0,0)),'constant')\n",
    "X_test = np.pad(X_test,((0,0),(2,2),(2,2),(0,0)),'constant')\n",
    "\n",
    "print(\"Updated Image Shape: {}\".format(X_train[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bc81b837b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#查看图片\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = random.randint(0,len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image,cmap='gray')\n",
    "plt.show()\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打乱数据\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "'''\n",
    "input: 32*32*c \n",
    "结构：\n",
    "layer1:卷积, output_size: 28*28*6\n",
    "activation: relu\n",
    "pooling: output_size: 14*14*6\n",
    "layer2:卷积, output_size: 10*10*6\n",
    "activation: relu\n",
    "pooling: output_size: 5*5*16\n",
    "flatten\n",
    "layer3:Full Connected 120 outputs\n",
    "activation: relu\n",
    "layer4:Full Connected 84 outputs\n",
    "activation: relu\n",
    "layer5:Full Connected 10 outputs\n",
    "'''\n",
    "\n",
    "from  tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    conv1_w = tf.Variable(tf.truncated_normal(shape=(5,5,1,6),mean=mu,stddev=sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x,conv1_w,strides=[1,1,1,1],padding='VALID') + conv1_b\n",
    "    \n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "    \n",
    "    conv2_w = tf.Variable(tf.truncated_normal(shape=(5,5,6,16),mean=mu,stddev=sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2   = tf.nn.conv2d(conv1,conv2_w,strides=[1,1,1,1],padding='VALID') + conv2_b\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    \n",
    "    fc0 = flatten(conv2)\n",
    "    \n",
    "    fc1_w = tf.Variable(tf.truncated_normal(shape=(400,120),mean=mu,stddev=sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0,fc1_w) + fc1_b\n",
    "    \n",
    "    fc1   = tf.nn.relu(fc1)\n",
    "\n",
    "    fc2_w = tf.Variable(tf.truncated_normal(shape=(120,84),mean=mu,stddev=sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(84))\n",
    "    fc2   = tf.matmul(fc1,fc2_w) + fc2_b\n",
    "    \n",
    "    fc2   = tf.nn.relu(fc2)\n",
    "\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,(None,32,32,1))\n",
    "y = tf.placeholder(tf.int32,(None))\n",
    "one_hot_y = tf.one_hot(y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-12-ae28af164121>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training pipline\n",
    "rate = 0.001\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y,logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.970\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.982\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.983\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.984\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.987\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_validation, y_validation)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Test Accuracy = 0.988\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    \n",
    "    test_accuracy = evaluate(X_test,y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
